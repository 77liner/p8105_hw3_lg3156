---
title: "p8105_hw3_lg3156"
author: "Liner Ge"
date: "2020/10/7"
output: github_document
---

```{r setup}
library(tidyverse)
library(p8105.datasets)
library(readxl)
library(dplyr)
library(rnoaa)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.height = 8,
  fig.width = 8,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes.

### How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are 134 aisles and most items from fresh vegetables.

### Make a plot

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

### Make a table

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
   group_by(aisle) %>% 
   count(product_name) %>% 
   mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

### Apples vs ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream") ) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

# Problem 2

### Load, tidy, and otherwise wrangle the data

```{r}
activity_df =
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "counts") %>% 
  drop_na(counts) %>% 
  mutate(
    weekday_weekend = case_when(
      day %in% c("Friday", "Monday", "Thursday", "Tuesday", "Wednesday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend",
    )
  ) %>% 
  mutate(
    week = as.factor(week),
    day_id = as.factor(day_id),
    minute = as.numeric(minute),
    weekday_weekend = as.factor(weekday_weekend),
    day = as.factor(day),
    counts = as.numeric(counts)
  ) %>% 
  mutate(
     day = forcats::fct_relevel(day,"Monday","Tuesday","Wednesday","Thursday","Friday", "Saturday","Sunday")
  ) %>% 
  group_by(week) %>% 
  arrange(day,.by_group = TRUE) %>% 
  relocate(day_id, week, weekday_weekend)
```

This dataset includes variables --  day_id, week, weekday_weekend, day, minute, and counts. This dateset has `r ncol(activity_df) ` columns and contains `r nrow(activity_df)` observations. 

### Traditional analyses of accelerometer data

```{r}
activity_df %>% 
  group_by(week, day) %>% 
  summarize(
    day_activity_counts = sum(counts)
  ) %>% 
  pivot_wider(
    names_from = day,
    values_from = day_activity_counts
  ) %>% 
  knitr::kable(digits = 2)
```

From this table, I can notice that on Saturday in last two week, the man had the least action. It seems like the man had less action on weekend than on weekdays. However, the counts of action is fluctuant among 5 weeks. Thus, I cannot find other trend apparently. 

### A plot showing the 24-hour activity

```{r}
activity_df %>% 
  ggplot(aes(x = minute, y = counts, color = day)) +
  geom_smooth(se = F) +
  scale_y_continuous(trans = "sqrt",
                     name = "Activity counts in minutes") +
  scale_x_continuous(name = "Hour",
                     breaks = c(120, 240, 360, 480, 600, 720, 840, 960, 1080, 1200, 1320, 1440), 
                     labels = c("2h", "4h", "6h", "8h", "10h", "12h","14h", "16h", "18h","20h", "22h", "24h")
                     ) +
  labs(
    title = "The 24-hour activity counts in 35 days",
    caption = "Data from accelerometer data")+
   viridis::scale_color_viridis(discrete = T,
                               name = "Day of the week")
```

In most of the days, the 63 year-old man's main activity time is between 10 am and 8 pm. There is no significant different between weekday and weekend. 

# Problem 3

Add data
```{r}
data("ny_noaa") 
```

### Do some data cleaning

```{r}
nynoaa_df =
  ny_noaa %>% 
  mutate_at(vars(date), as.factor) %>%
  separate(date, into = c("year", "month", "day")) %>% 
  mutate_at(vars(prcp, tmax, tmin, snow), as.numeric) %>%
  mutate(
    prcp = prcp/10,
    tmax = tmax/10,
    tmin = tmin/10,
    snow = case_when(
      snow <0 ~ 0,
      snow >= 0 ~ snow)
  ) %>% 
  mutate_at(vars(year, month, day), as.factor)

skimr::skim_without_charts(nynoaa_df)
```

This dataset has `r nrow(nynoaa_df)` rows and `r ncol(nynoaa_df)` columns. It contains weather data for all NY states from 1981/01/01 to 2010/12/31. There are 9 valuables -- id, year, month, day, prcp, snow, snwd, tmax, and tmin. The type of "id" is character; the type of "year", "month", "day" are factor; the type of "prcp", "snow", "snwd", "tmax", and "tmin" are numeric and they all have missing data. The number of missing data of tmax and tmin are extremly high, so this is an issue. 

### Snowfall

```{r}
nynoaa_df %>% 
  count(snow, na.rm = T) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank == 1)
```

The most commonly observed values is 0. Because in most of days, there isn't a snowfall.

### A plot showing the average max temperature
```{r}
january =
  nynoaa_df %>% 
  filter(month == "01") %>% 
  group_by(id,year,month) %>% 
  summarise(tmax_mean = mean(tmax,na.rm = T)) %>% 
  drop_na() %>% 
  ggplot(aes(x = year, y = tmax_mean, color = id)) +
  geom_point(alpha = 0.3, size = 0.2) +
  geom_path(aes(group = id), alpha = 0.3, size = 0.2) +
  theme(
    legend.position = 'none',
    plot.title = element_text(lineheight = 3, face = "bold", color = "black", size = 8),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 5),
    axis.text.y = element_text(size = 8)
    ) +
  labs(
    x = "Year",
    y = "Temperature(C)",
    title = "Max temperature in January in each station across years"
    )
    

 july =
  nynoaa_df %>% 
  filter(month == "07") %>% 
  group_by(id,year,month) %>% 
  summarise(tmax_mean = mean(tmax,na.rm = T)) %>% 
  drop_na() %>% 
  ggplot(aes(x = year, y = tmax_mean, color = id)) +
  geom_point(alpha = 0.3, size = 0.2) +
  geom_path(aes(group = id), alpha = 0.3, size = 0.2) +
  theme(
    legend.position = 'none',
    plot.title = element_text(lineheight = 3, face = "bold", color = "black", size = 8),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 5),
    axis.text.y = element_text(size = 8)
    ) +
  labs(
    x = "Year",
    y = "Temperature(C)",
    title = "Max temperature in July in each station across years"
    )
 
 january/july
```

In January, the max temperature fluctuate between -10C and 10C. In July the max temperature fluctuate between 20C and 33C. From this plot, we can see many outliers. From "Max temperature in January in each station across years" we can see 1994 and 2004 had relative low temperature and 1990, 1998, 2002 had relative high temperature in January. From "Max temperature in July in each station across years" we can see 1986, 1992, 2000, 2009 had relative low temperature and 1983, 1999, 2010 had relative high temperature in July.

Outliers of max temperature in January in each station across years
```{r} 
nynoaa_df %>% 
  filter(month == "01") %>% 
  group_by(id,year,month) %>% 
  summarise(tmax_mean = mean(tmax,na.rm = T)) %>% 
  drop_na() %>% 
  filter(tmax_mean > 10 | tmax_mean < -10) %>% 
  knitr::kable(digits = 1)
```

Outliers of max temperature in July in each station across years
```{r} 
nynoaa_df %>% 
  filter(month == "07") %>% 
  group_by(id,year,month) %>% 
  summarise(tmax_mean = mean(tmax,na.rm = T)) %>% 
  drop_na() %>% 
  filter(tmax_mean > 33 | tmax_mean < 20) %>% 
  knitr::kable(digits = 1)
```

### A two-panel plot showing temperature and snowfall

```{r}
temperature =
  nynoaa_df %>% 
  drop_na(tmax, tmin) %>% 
  pivot_longer(
    tmax:tmin,
    names_to = "tmax_tmin",
    values_to = "temp"
  ) %>% 
  ggplot(aes(x = year, y = temp)) +
  geom_boxplot(aes(color = tmax_tmin), alpha = 0.5, outlier.size = 0.2) +
  theme(
    plot.title = element_text(lineheight = 3, face = "bold", color = "black", size = 8),
    legend.position = 'right',
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 5),
    axis.text.y = element_text(size = 8)
    ) +
  labs(
    x = "Year",
    y = "Temperature (C)",
    title = "Tmax vs Tmin for years"
    )

snowfall = 
  nynoaa_df %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = year, y = snow)) + 
  geom_violin(color = "purple" , fill = "yellow") +
  theme(
    plot.title = element_text(lineheight = 3, face = "bold", color = "black", size = 8),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 5),
    axis.text.y = element_text(size = 8)) +
  labs(
    x = "Year",
    y = "Snowfall (mm)",
    title = "The snowfall values separately by year"
    )

temperature / snowfall
```

From "Tmax vs Tmin for years", there seems to be no significant change of tmax or tmin for different years. There is approximately a difference of 12C between tmax and tmin in each year. From "The snowfall values separately by year", there seems to be no significant change of snowfall values for different years. The value of snowfall depth concentrates on 0-25mm, 50mm, and 75mm for each year.
